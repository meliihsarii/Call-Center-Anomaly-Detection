{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AUTOENCODER MODEL",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHqzA8Sz8xO1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import stats\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A1Esmyw85tL"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxivrT3G1GAU"
      },
      "source": [
        "#Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WfOeQNm1H-i"
      },
      "source": [
        "df_s= pd.read_csv(\"/content/drive/MyDrive/sariyer_sample.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDsvei0z-QeQ"
      },
      "source": [
        "df_s.shape()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPtG5WE31O3d"
      },
      "source": [
        "#Visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh4EKFsJ1SSe"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "df_s.plot(legend=False, ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knzOz4gkG8gC"
      },
      "source": [
        "print('Box plot visualization:')\n",
        "value.plot(kind='box', figsize = (10,4))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anpnKbSEHGsl"
      },
      "source": [
        "import seaborn as sns\n",
        "fig,ax1=plt.subplots(ncols=1,figsize=(8,5))\n",
        "ax1.set_title(\"Scaling\")\n",
        "sns.kdeplot(value[\"value\"],ax=ax1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx_UELAM1YUl"
      },
      "source": [
        "#Prepare training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVO-7h101gML"
      },
      "source": [
        "training_mean = df_s.mean()\n",
        "training_std = df_s.std()\n",
        "df_training_value = (selection2 - training_mean) / training_std\n",
        "print(\"Number of training samples:\", len(df_training_value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9gIXv7x1zM-"
      },
      "source": [
        "Create sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Ah85uAJXpr"
      },
      "source": [
        "# helper function\n",
        "def create_dataset(X, y, time_steps=1):\n",
        "  a, b = [], []\n",
        "  for i in range(len(X) - time_steps):\n",
        "     v = X.iloc[i:(i + time_steps)].values\n",
        "     a.append(v)\n",
        "     b.append(y.iloc[i + time_steps])\n",
        "  return np.array(a), np.array(b)\n",
        "\n",
        "n_steps =96\n",
        "# reshape to 3D [n_samples, n_steps, n_features]\n",
        "X_train, y_train = create_dataset(train[['Value']], train['value'], n_steps)\n",
        "X_test, y_test = create_dataset(test[['Value']], test['value'], n_steps)\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UkThhcU13ZB"
      },
      "source": [
        "#Build a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWy62QheT82q"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
        "        layers.Conv1D(\n",
        "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Dropout(rate=0.2),\n",
        "        layers.Conv1D(\n",
        "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Conv1DTranspose(\n",
        "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Dropout(rate=0.2),\n",
        "        layers.Conv1DTranspose(\n",
        "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
        "    ]\n",
        ")\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsmPnJZd2R4-"
      },
      "source": [
        "#Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "248CUQAUTmdX"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
        "    ],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrZx39fJ2a9f"
      },
      "source": [
        "#Detecting anomalies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e06mu3eI6ycS"
      },
      "source": [
        "We will detect anomalies by determining how well our model can reconstruct the input data.\n",
        "\n",
        "Find MAE loss on training samples.\n",
        "Find max MAE loss value. This is the worst our model has performed trying to reconstruct a sample. We will make this the threshold for anomaly detection.\n",
        "If the reconstruction loss for a sample is greater than this threshold value then we can infer that the model is seeing a pattern that it isn't familiar with. We will label this sample as an anomaly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UBszD1p4qIr"
      },
      "source": [
        "# Get train MAE loss.\n",
        "x_train_pred = model.predict(x_train)\n",
        "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
        "\n",
        "plt.hist(train_mae_loss, bins=50)\n",
        "plt.xlabel(\"Train MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "# Get reconstruction loss threshold.\n",
        "threshold = np.max(train_mae_loss)\n",
        "print(\"Reconstruction error threshold: \", threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Fao-izTou4"
      },
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMk0g6sPz1cd"
      },
      "source": [
        "plt.plot(x_train[0])\n",
        "plt.plot(x_train_pred[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-778_747CXw"
      },
      "source": [
        "# Detect all the samples which are anomalies.\n",
        "anomalies = test_mae_loss > threshold\n",
        "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
        "print(\"Indices of anomaly samples: \", np.where(anomalies))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf2-q8Tg7HpZ"
      },
      "source": [
        "# data i is an anomaly if samples [(i - timesteps + 1) to (i)] are anomalies\n",
        "anomalous_data_indices = []\n",
        "for data_idx in range(TIME_STEPS - 1, len(df_test_value) - TIME_STEPS + 1):\n",
        "    if np.all(anomalies[data_idx - TIME_STEPS + 1 : data_idx]):\n",
        "        anomalous_data_indices.append(data_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDYza-188of"
      },
      "source": [
        "df_s[\"Outliers\"]=pd.Series(model.predict(df_s[[\"value\"]])).apply(lambda x: \"yes\" if( x==1) else \"no\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}